{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Simulation\"\n",
        "---\n",
        "\n",
        "```{r setup}\n",
        "#| echo: false\n",
        "#| message: false\n",
        "#| warning: false\n",
        "library(knitr)\n",
        "library(reticulate)\n",
        "venv_paths <- read.csv(\"venv_paths.csv\")\n",
        "id <- match(Sys.info()[\"nodename\"], venv_paths$nodename)\n",
        "use_virtualenv(venv_paths$path[id])\n",
        "```\n",
        "\n",
        "## Introduction {#sec-simulation}\n",
        "\n",
        "The objective of any simulation study is to estimate an expectation $E(X)$.\n",
        "Simulation studies involve the use of a computer to generate independent copies \n",
        "of the random variable of interest $X$. Here are a couple of examples where \n",
        "simulation studies would be applicable.\n",
        "\n",
        "::: {style=\"background-color: #D5D1D1; padding: 20px\" #exm-ins-01}\n",
        "\n",
        "### Insurance Claims\n",
        "\n",
        "Before the financial year begins, an insurance company has to decide how much\n",
        "cash to keep, in order to pay out the claims for that year. Suppose that \n",
        "claims are independent of each other and are distributed as $Exp(1/200)$[^10-exp]\n",
        "dollars. Also suppose that the number of claims in a year is a Poisson\n",
        "random variable with mean 8.2.\n",
        "\n",
        "An actuary has been asked to determine the size of the reserve fund that should\n",
        "be set up, and he recommends $12,000. We might consider answering the following\n",
        "question using simulation: \n",
        "\n",
        "* What is the probability that the total claims will exceed the reserve fund?\n",
        "\n",
        "If we let $Y$ be the random variable representing the total sum of claims, we\n",
        "are interested in estimating $P(Y > 12000)$. Since probabilities are expectations,\n",
        "we can use simulation to estimate this value.\n",
        "\n",
        "[^10-exp]: $f_X(x) = \\frac{1}{200} \\exp(-x/200),\\; x > 0$\n",
        "\n",
        ":::\n",
        "\n",
        "<br>\n",
        "\n",
        "Here is a slightly more sophisticated example.\n",
        "\n",
        "::: {style=\"background-color: #D5D1D1; padding: 20px\" #exm-sandwich-01}\n",
        "\n",
        "### Sandwich Shop Closing Time\n",
        "\n",
        "Suppose that you run a sandwich shop, which is open from 9am till 5pm. Your\n",
        "philosophy has always been to serve every customer who has entered before 5pm,\n",
        "even if that requires you to stay back until they have been served. You\n",
        "would like to estimate the mean amount of overtime you have to work.\n",
        "\n",
        "If you are willing to assume that the inter-arrival times of customers is \n",
        "$Exp(3)$ hours, then it is possible to simulate this process to estimate the \n",
        "mean time that you would have to remain open, beyond 5pm.\n",
        "\n",
        ":::\n",
        "\n",
        "The two examples above are known as Discrete Event Simulations. In our course, \n",
        "we will not get to working with such scenarios. However, we will try to understand\n",
        "and familiarise ourselves with the basic building blocks of simulation studies.\n",
        "For more knowledge, do enrol yourself in ST3247!\n",
        "\n",
        "The basic steps in a simulation study are:\n",
        "\n",
        "1. Identify the random variable of interest and write a program to simulate it.\n",
        "2. Generate an iid sample $X_1, X_2, \\ldots, X_n$ using this program.\n",
        "3. Estimate $E(X)$ using $\\bar{X}$.\n",
        "\n",
        "This is sometimes referred to as Monte Carlo Simulation.  Before proceeding,\n",
        "let us refresh our knowledge of the properties of the sample mean.\n",
        "\n",
        "## Theory\n",
        "\n",
        "There are two important theorems that simulation studies rely on. The first \n",
        "is the Strong Law of Large Numbers (SLLN).\n",
        "\n",
        "\n",
        "::: {style=\"background-color: #D5D1D1; padding: 20px\" #thm-slln}\n",
        "\n",
        "### Strong Law of Large Numbers\n",
        "\n",
        "If $X_1, X_2, \\ldots, X_n$ are independent and identically distributed with \n",
        "$E(X) < \\infty$, then \n",
        "$$\n",
        "\\bar{X} =\\frac{1}{n} \\sum_{i=1}^n X_i\\rightarrow E(X) \\quad \\text{with probability 1.}\n",
        "$$\n",
        "\n",
        ":::\n",
        "\n",
        "In the simulation context, it means that as we generate more and more samples\n",
        "(i.e. increase $n$), our sample mean $\\bar{X}$ converges to the desired value \n",
        "$E(X)$, *no matter what the distribution of $X$ is.*\n",
        "\n",
        "The second theorem that aids us is the Central Limit Theorem (CLT).\n",
        "\n",
        "::: {style=\"background-color: #D5D1D1; padding: 20px\" #thm-clt}\n",
        "\n",
        "### Central Limit Theorem\n",
        "\n",
        "Let $X_1, X_2, \\ldots, X_n$ be i.i.d., and suppose that \n",
        "\n",
        "*  $-\\infty < E(X_1) = \\mu < \\infty$. \n",
        "* $Var(X_1) = \\sigma^2 < \\infty$.\n",
        "\n",
        "Then \n",
        "$$\n",
        "\\frac{\\sqrt{n} (\\bar{X} - \\mu)}{\\sigma} \\Rightarrow N(0,1)\n",
        "$$\n",
        "where $\\Rightarrow$ denotes convergence in distribution.\n",
        ":::\n",
        "\n",
        "This is sometimes informally interpreted to mean that when $n$ is\n",
        "large, $\\bar{X}$ is approximately Normal with mean $\\mu$ and variance\n",
        "$\\sigma^2/n$. In the simulation context, we can use this theorem to obtain a\n",
        "confidence interval for the expectation that we are estimating.\n",
        "\n",
        "Also take note of the following properties of the sample mean and variance:\n",
        "\n",
        "::: {style=\"background-color: #D5D1D1; padding: 20px\" #thm-unbiased}\n",
        "\n",
        "### Sample Estimates\n",
        "\n",
        "It can be shown that both the sample mean and sample standard deviation are \n",
        "unbiased estimators.\n",
        "$$\n",
        "E(\\bar{X}) = E(X), \\quad E(s^2) = \\sigma^2\n",
        "$$\n",
        "where $s^2 = \\frac{\\sum (X_i - \\bar{X})^2}{n-1}$.\n",
        ":::\n",
        "\n",
        "To obtain a $(1-\\alpha)100%$ confidence interval for $\\mu$, we use the following \n",
        "formula, from the CLT:\n",
        "\n",
        "$$\n",
        "\\bar{X} \\pm z_{1-\\alpha/2} \\frac{s}{\\sqrt{n}}\n",
        "$$\n",
        "\n",
        "When our goal is to estimate a probability $p$, we have to introduce a\n",
        "corresponding indicator variable $X$ such that \n",
        "\n",
        "$$\n",
        "X = \n",
        "\\begin{cases}\n",
        "1 & \\text{with probability $p$} \\\\\n",
        "0 & \\text{with probability $1- p$}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "In this case, the formula for the CI becomes \n",
        "$$\n",
        "\\bar{X} \\pm z_{1-\\alpha/2} \\sqrt{\\frac{\\bar{X}(1-\\bar{X})}{n}}\n",
        "$$\n",
        "\n",
        "## Generating Random Variables in R and Python\n",
        "\n",
        "Both R and Python contain built-in routines for generating random variables from\n",
        "common \"named\" distributions, e.g. Normal, Uniform, Gamma, etc. All software\n",
        "that can generate random variables utilise Pseudo-Random Number Generators\n",
        "(PRNG). These are routines that generate sequences of deterministic numbers with\n",
        "very very long cycles. However, since they pass several tests of randomness,\n",
        "they can be treated as truly random variables for all intents and purposes.\n",
        "\n",
        "In both software, we can set the \"seed\". This initialises the random number\n",
        "generator. When we reset the seed, we can reproduce the stream of random\n",
        "variables exactly. This feature exists:\n",
        "\n",
        "1. For debugging purposes,\n",
        "2. To allow us to study the sensitivity of our results to the seed.\n",
        "\n",
        "::: {style=\"background-color: #D5D1D1; padding: 20px\" #exm-rng-1}\n",
        "\n",
        "### Random Variable Generation\n",
        "\n",
        "::: {.panel-tabset}\n",
        "\n",
        "#### R code \n",
        "\n",
        "In R, all the functions for generating random variables begin with `r` (for \n",
        "random). Here are a few such functions:\n",
        "\n",
        "| Function name | Random Variable |\n",
        "|----------|----------|\n",
        "| `rnorm`  | Normal   |\n",
        "| `runif`  | Uniform  |\n",
        "| `rgamma` | Gamma    |\n",
        "| `rpois`  | Poisson  |\n",
        "| `rbinom` | Binomial |\n",
        "\n",
        "```{r r-rng-1}\n",
        "#| fig-align: center\n",
        "#R \n",
        "set.seed(2137)\n",
        "\n",
        "opar <- par(mfrow=c(1,3))\n",
        "Y <- rgamma(50, 2, 3)\n",
        "hist(Y)\n",
        "\n",
        "W <- rpois(50, 1.3) # 50 obs from Pois(1.3)\n",
        "barplot(table(W))\n",
        "\n",
        "Z <- rbinom(50, size=2, 0.3) # 50 obs from Binom(2, 0.3)\n",
        "barplot(table(Z))\n",
        "\n",
        "par(opar)\n",
        "\n",
        "```\n",
        "\n",
        "#### Python code \n",
        "\n",
        "In Python, we can generate random variables using `numpy` and/or `scipy`. In our \n",
        "course, we shall use the `scipy` routines because its implementation is closer \n",
        "in spirit to R.\n",
        "\n",
        "| Function name | Random Variable |\n",
        "|----------|----------|\n",
        "| `norm`  | Normal   |\n",
        "| `uniform`  | Uniform  |\n",
        "| `gamma` | Gamma    |\n",
        "| `poisson`  | Poisson  |\n",
        "| `binom` | Binomial |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import binom, gamma, norm, poisson\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rng = np.random.default_rng(2137)\n",
        "fig, ax = plt.subplots(1, 3, figsize=(8,4))\n",
        "\n",
        "ax1 = plt.subplot(131)\n",
        "r = gamma.rvs(2, 3, size=50, random_state=rng)\n",
        "ax1.hist(r);\n",
        "\n",
        "ax1 = plt.subplot(132)\n",
        "r = poisson.rvs(1.3, size=50, random_state=rng)\n",
        "ax1.hist(r);\n",
        "\n",
        "ax1 = plt.subplot(133)\n",
        "r = binom.rvs(2, 0.3, size=50, random_state=rng)\n",
        "ax1.hist(r);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "## Monte-Carlo Integration\n",
        "\n",
        "Suppose we wish to evaluate\n",
        "\n",
        "$$\n",
        "\\int_{-\\infty}^{\\infty} h(x) f(x) \\text{d}x\n",
        "$$\n",
        "where $f(x)$ is a pdf. The integral above is in fact equal to $E(h(X))$, where\n",
        "$X \\sim f$. Hence we can use everything we have discussed so far, to evaluate\n",
        "the expression using simulation! Everything depends on:\n",
        "\n",
        "1. Being able to introduce a pdf to the integral\n",
        "2. Being to able to simulate from that pdf. \n",
        "\n",
        "::: {.callout-important}\n",
        "It is critical that the support of the pdf is the same as the range of integration.\n",
        ":::\n",
        "\n",
        "::: {style=\"background-color: #D5D1D1; padding: 20px\" #exm-mc-1}\n",
        "\n",
        "### Monte Carlo Integration over (0,1)\n",
        "\n",
        "Suppose Suppose we wish to evaluate\n",
        "$$\n",
        "\\theta = \\int_0^1 e^{2x} dx = \\int_0^1 e^{2x} \\cdot 1\\; dx \n",
        "$$\n",
        "\n",
        "We can identify that this is equal to $E(h(X))$ where \n",
        "\n",
        "* $X \\sim Unif(0,1)$.   \n",
        "* $h(X) = e^{2x}$\n",
        "\n",
        "Thus we can follow this pseudo-code:\n",
        "\n",
        "1. Generate $X_1,X_2,\\ldots,X_n \\sim Unif(0,1)$.\n",
        "2. Estimate the integral using\n",
        "$$\n",
        "\\frac{1}{n} \\sum_{i=1}^n e^{2 X_i}\n",
        "$$\n",
        "\n",
        "In this simple case, we can in fact work out analytically that the integral is \n",
        "equal to\n",
        "$$\n",
        "\\frac{1}{2}(e^2 - 1) = 3.195\n",
        "$$\n",
        "\n",
        "::: {.panel-tabset}\n",
        "\n",
        "#### R code \n",
        "\n",
        "```{r r-mc-1}\n",
        "set.seed(2138)\n",
        "X <- runif(50000, 0, 1)\n",
        "hX <- exp(2*X)\n",
        "(mc_est <- mean(hX))\n",
        "```\n",
        "\n",
        "#### Python code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from scipy.stats import uniform\n",
        "\n",
        "X = uniform.rvs(0,1, size=50000, random_state=rng)\n",
        "hX = np.exp(2*X)\n",
        "hX.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "## Simulation Studies\n",
        "\n",
        "In this section, we shall touch on how we can use simulation in some scenarios that are\n",
        "closer to the real world.\n",
        "\n",
        "### Confidence Intervals\n",
        "\n",
        "The usual 95% confidence interval for a mean is given by \n",
        "$$\n",
        "\\bar{X} \\pm t_{0.025} s/\\sqrt{n}\n",
        "$$\n",
        "where $t_{0.025}$ is the 0.025 quantile of the t-distribution with $n-1$\n",
        "degrees. The resulting interval should contain the true mean in 95% of the\n",
        "experiments. However, it is derived under the assumption that the data is\n",
        "Normally distributed. Let us see if it still works if the data is from an\n",
        "asymmetric distribution: $Pois(0.5)$.\n",
        "\n",
        "\n",
        "::: {style=\"background-color: #D5D1D1; padding: 20px\" #exm-ci-1}\n",
        "\n",
        "### Coverage of Confidence Interval\n",
        "\n",
        "::: {.panel-tabset}\n",
        "\n",
        "#### R code \n",
        "\n",
        "```{r r-ci-95}\n",
        "# R \n",
        "set.seed(2139)\n",
        "output_vec <- rep(0, length=100)\n",
        "n <- 20\n",
        "lambda <- 0.5\n",
        "for(i in 1:length(output_vec)) {\n",
        "  X <- rpois(15, .5)\n",
        "  Xbar <- mean(X)\n",
        "  s <- sd(X)\n",
        "  t <- qt(0.975, n-1)\n",
        "  CI <- c(Xbar - t*s/sqrt(n), Xbar + t*s/sqrt(n))\n",
        "  if(CI[1] < lambda & CI[2] > lambda) {\n",
        "    output_vec[i] <- 1\n",
        "  }\n",
        "}\n",
        "mean(output_vec)\n",
        "```\n",
        "\n",
        "#### Python code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rng = np.random.default_rng(2137)\n",
        "output_vec = np.zeros(100)\n",
        "n = 20\n",
        "lambda_ = 0.5\n",
        "for i in range(100):\n",
        "    X = poisson.rvs(0.5, size=15, random_state=rng)\n",
        "    Xbar = X.mean()\n",
        "    s = X.std()\n",
        "    t = norm.ppf(0.975)\n",
        "    CI = [Xbar - t*s/np.sqrt(n), Xbar + t*s/np.sqrt(n)]\n",
        "    if CI[0] < lambda_ and CI[1] > lambda_:\n",
        "        output_vec[i] = 1\n",
        "output_vec.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "### Type I Error\n",
        "\n",
        "Consider the independent two-sample $t$-test that we introduced in topic 7. The\n",
        "formal set-up also includes the assumption that our data arises from a Normal\n",
        "distribution. According to the theory of the $t$-test, if both groups have the\n",
        "same mean, we should *falsely* reject the null hypothesis 10% of the time if we\n",
        "perform it at 10% significance level. Let us assess if this is what actually\n",
        "happens.\n",
        "\n",
        "::: {style=\"background-color: #D5D1D1; padding: 20px\" #exm-t-test-1}\n",
        "\n",
        "### T-test Type I Error\n",
        "\n",
        "::: {.panel-tabset}\n",
        "\n",
        "#### R code \n",
        "\n",
        "```{r r-test-1}\n",
        "generate_one_test <- function(n=100) {\n",
        "  X <- rnorm(n)\n",
        "  Y <- rnorm(n)\n",
        "  t_test <- t.test(X, Y,var.equal = TRUE)\n",
        "  # extract the p-value from the t_test\n",
        "  if(t_test$p.value < 0.10) \n",
        "    return(1L) \n",
        "  else \n",
        "    return(0L)\n",
        "}\n",
        "\n",
        "set.seed(11)\n",
        "output_vec <- vapply(1:2000, \n",
        "                     function(x) generate_one_test(), \n",
        "                     1L)\n",
        "mean(output_vec)\n",
        "```\n",
        "\n",
        "#### Python code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def generate_one_test(n=100):\n",
        "    X = norm.rvs(0, 1, size=n, random_state=rng)\n",
        "    Y = norm.rvs(0, 1, size=n, random_state=rng)\n",
        "    t_test = stats.ttest_ind(X, Y, equal_var=True)\n",
        "    if t_test.pvalue < 0.10:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "output_vec = np.array([generate_one_test() for j in range(2000)])\n",
        "output_vec.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "### Newspaper Inventory\n",
        "\n",
        "::: {style=\"background-color: #D5D1D1; padding: 20px\" #exm-newspaper-1}\n",
        "\n",
        "Suppose that daily demand for newspaper is approximately gamma distributed, with \n",
        "mean 10,000 and variance 1,000,000. The newspaper prints and distributes 11,000 \n",
        "copies each day. The profit on each newspaper sold is $1, and the loss on each \n",
        "unsold newspaper is 0.25. Formally, the daily profit function h is\n",
        "\n",
        "$$\n",
        "h(X) = \n",
        "\\begin{cases}\n",
        "11000 & \\text{if } X ≥ 11000 \\\\\n",
        "\\lfloor X \\rfloor + (11000 - \\lfloor X \\rfloor)(−0.25) & \\text{if } X < 11000\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "where $X$ represents the daily demand. Let us estimate the expected daily \n",
        "profit using simulation.\n",
        "\n",
        "::: {.panel-tabset}\n",
        "\n",
        "#### R code \n",
        "\n",
        "```{r r-newspaper-1}\n",
        "# R code to estimate the expected daily profit\n",
        "set.seed(2141)\n",
        "n <- 10000\n",
        "X <- rgamma(n, 100, rate=1/100)\n",
        "hX <- ifelse(X >= 11000, 11000, floor(X) + (11000 - floor(X)) * (-0.25))\n",
        "#mean(hX)\n",
        "\n",
        "# 90% CI for the mean\n",
        "s <- sd(hX)\n",
        "q1 <- qnorm(0.95)\n",
        "CI <- c(mean(hX) - q1*s/sqrt(n), mean(hX) + q1*s/sqrt(n))\n",
        "cat(\"The 90% CI for the mean is (\", format(CI[1], digits=2, nsmall=2), \", \", \n",
        "    format(CI[2], digits=2, nsmall=2), \").\\n\", sep=\"\")\n",
        "```\n",
        "\n",
        "#### Python code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n = 10000\n",
        "X = gamma.rvs(100, scale=100, size=n, random_state=rng)\n",
        "hX = np.where(X >= 11000, 11000, np.floor(X) + (11000 - np.floor(X)) * (-0.25))\n",
        "\n",
        "# 90% CI for the mean\n",
        "Xbar = hX.mean()\n",
        "s = hX.std()\n",
        "t = norm.ppf(0.95)\n",
        "CI = [Xbar - t*s/np.sqrt(n), Xbar + t*s/np.sqrt(n)]\n",
        "print(f\"The 90% CI for the mean is ({CI[0]: .3f}, {CI[1]: .3f}).\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "## Resampling Methods\n",
        "\n",
        "The next section introduces two techniques that are based on resampling the data.\n",
        "\n",
        "### Permutation Test {#sec-perm-test}\n",
        "\n",
        "Consider the two-sample t-test that we introduced in topic 06. This parametric \n",
        "test requires us to check if the data from the two groups came from Normal distributions.\n",
        "The non-parametric version requires each group to have at least 10 observations.\n",
        "What if our data satisfies neither criteria? \n",
        "\n",
        "The permutation test is applicable in such a situation. It makes no distributional\n",
        "assumptions whatsoever on the data. Here is pseudo-code for how it works:\n",
        "\n",
        "1. Compute the difference in group means. This observed difference is the test \n",
        "   statistic.\n",
        "2. Treating the observed values as fixed, combine the two vectors of observations.\n",
        "3. Permute the observations, and then re-assign them to the two groups.\n",
        "4. Compute the difference between the group means.\n",
        "5. Repeat steps 2 - 4 multiple times (order of 1000). \n",
        "\n",
        "The $p$-value for the null hypothesis can be computed by computing the proportion of \n",
        "simulated statistics that were larger in absolute value than the observed one.\n",
        "\n",
        "\n",
        "::: {style=\"background-color: #D5D1D1; padding: 20px\" #exm-abalone-1-repeat}\n",
        "### Abalone Data \n",
        "\\index{Abalone!permutation test}\n",
        "\n",
        "In the abalone dataset, this was the output from the t-test:\n",
        "\n",
        "```{r r-abalone-1}\n",
        "abl <- read.csv(\"data/abalone_sub.csv\")\n",
        "x <- abl$viscera[abl$gender == \"M\"]\n",
        "y <- abl$viscera[abl$gender == \"F\"]\n",
        "\n",
        "t.test(x, y, var.equal=TRUE)\n",
        "```\n",
        "\n",
        "This would be the procedure for a permutation test:\n",
        "\n",
        "```{r abalone-2}\n",
        "#| fig-align: center\n",
        "#| \n",
        "d1 <- mean(x)  - mean(y)\n",
        "print(d1)\n",
        "\n",
        "generate_one_perm <- function(x, y) {\n",
        "  n1 <- length(x)\n",
        "  n2 <- length(y)\n",
        "  xy <- c(x,y)\n",
        "  xy_sample <- sample(xy)\n",
        "  d1 <- mean(xy_sample[1:n1]) - mean(xy_sample[-(1:n1)])\n",
        "  d1\n",
        "}\n",
        "sampled_diff <- replicate(2000, generate_one_perm(x,y))\n",
        "hist(sampled_diff)\n",
        "\n",
        "(p_val <- 2*mean(sampled_diff > d1))\n",
        "```\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "### Bootstrapping\n",
        "\n",
        "The video on Canvas provides a very brief introduction to bootstrapping. One of\n",
        "the greatest benefits of the bootstrap is the ability to provide confidence\n",
        "intervals for estimators for which we may not have the know-how to derive\n",
        "analytic or asymptotic results.\n",
        "\n",
        "Consider obtaining a confidence interval for the trimmed mean, that we\n",
        "encountered in @sec-robust.\n",
        "\n",
        "::: {style=\"background-color: #D5D1D1; padding: 20px\" #exm-chem-1}\n",
        "\\index{Copper!bootstrap CI}\n",
        "\n",
        "This is how we can use bootstrapping to obtain a confidence interval for a \n",
        "trimmed mean.\n",
        "\n",
        "```{r}\n",
        "library(MASS)\n",
        "\n",
        "mean(chem)\n",
        "t.test(chem)\n",
        "## [1] 4.280417\n",
        "```\n",
        "\n",
        "Notice how the CI from the non-robust technique is very wide.\n",
        "\n",
        "```{r}\n",
        "library(boot)\n",
        "\n",
        "stat_fn <- function(d, i) {\n",
        "  b <- mean(d[i], trim=0.1)\n",
        "  b\n",
        "}\n",
        "boot_out <- boot(chem, stat_fn, R = 1999, stype=\"i\")\n",
        "# Returns two types of bootstrap intervals:\n",
        "boot.ci(boot.out = boot_out, type=c(\"perc\", \"bca\"))\n",
        "```\n",
        "\n",
        "The boot function requires a function (`stat_fn`) that computes the statistic\n",
        "from the bootstrapped sample.  Note that the intervals returned  from the trimmed \n",
        "mean are much narrower.\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "## Summary\n",
        "\n",
        "In this chapter, we have seen how simulation studies can be used to estimate \n",
        "expectations. Although we have restricted ourselves to very straightforward\n",
        "examples, the same principles can be applied to more complex scenarios. \n",
        "\n",
        "In particular, there are three types of simulation models widely used to \n",
        "model complex systems:\n",
        "\n",
        "1. Agent-based models. These are regularly used to model the interactions of \n",
        "   agents in a system, e.g. humans.\n",
        "2. Discrete Event Simulations. These are used to model systems where events\n",
        "   occur at discrete points in time. Typically, these are systems where there is an\n",
        "   arrival of entities, a service, and a departure.\n",
        "3. Process modeling. This approach is used to model the flow of entities through\n",
        "   a system. They are sometimes also referred to as compartment models.\n",
        "\n",
        "Please refer to the sections below for more information. For our course,\n",
        "please be familiar with the basic building blocks of simulation studies:\n",
        "\n",
        "1. Generate iid samples, and then\n",
        "2. Compute the sample mean, and the CI for the true mean.\n",
        "\n",
        "## References\n",
        "\n",
        "### Website References {#sec-web-ref-10}\n",
        "\n",
        "1. Some GUI-based software for simulation:\n",
        "   * [Anylogic](https://www.anylogic.com/) A very very powerful software for \n",
        "     agent-based modeling.\n",
        "   * [Arena](https://www.rockwellautomation.com/en-us/products/software/arena-simulation.html) A discrete event simulator, with a free academic license.\n",
        "   * [Netlogo](https://ccl.northwestern.edu/netlogo/) An open source software for agent-based modeling.\n",
        "2. Python software:\n",
        "   * [simpy](https://simpy.readthedocs.io/en/latest/) for discrete event simulations.\n",
        "   * [mesa](https://github.com/projectmesa/mesa) for agent-based modeling.\n",
        "3. R software:\n",
        "   * [simmer](https://r-simmer.org/) for discrete event simulation\n",
        "4. [scipy documentation](https://docs.scipy.org/doc/scipy/reference/stats.html#probability-distributions)\n",
        "5. [Introduction to Bootstrapping](https://online.stat.psu.edu/stat555/node/119/)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/home/viknesh/penvs/p310/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}