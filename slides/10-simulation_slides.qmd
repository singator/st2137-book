---
title: "Simulation"
format: 
  beamer:
    aspectratio: 169
    theme: Boadilla
    navigation: empty
    colortheme: lily
    footer: "ST2137-2520"

execute:
  echo: true
---

```{r}
#| echo: false
library(knitr)
```

## Objective of Simulation Studies {.smaller}

* To estimate the an expectation $E(X)$.
* Simulation studies involve the use of a computer to generate independent copies 
  of the random variable of interest $X$.

## Example 1 {.smaller}

### Insurance Claims

* Before an FY, an insurance company has to decide how much cash to keep.
* Suppose that claims are independent of each other and are distributed as 
  Exp(1/200)[^1] dollars.
* An actuary recommends $12,000.
* What is the probability that the total claims will exceed the reserve fund?
* If we let $Y$ be the random variable representing the total sum of claims, we
  are interested in estimating $P(Y > 12000)$. 
* Since probabilities are expectations, we can use simulation to estimate this value.

[^1]: $f_X(x) = \frac{1}{200} \exp(-x/200),\; x > 0$

## Example 2 {.smaller}

### Sandwich Shop Closing Time

* Suppose that you run a sandwich shop, which is open from 9am till 5pm. 
* You would like to estimate the mean amount of time you have to work overtime.
* You are willing to assume that the inter-arrival times of customers is 
  $Exp(3)$ hours,  
* Then it is possible to simulate this process to estimate the mean time that
  you would have to remain after 5pm.

## Basic Steps {.smaller}

The basic steps in a simulation study are:

1. Identify the random variable of interest and write a program to simulate it.
2. Generate an iid sample $X_1, X_2, \ldots, X_n$ using this program.
3. Estimate $E(X)$ using $\bar{X}$.

This is sometimes referred to as Monte Carlo Simulation.

## Strong Law of Large Numbers {.smaller}

If $X_1, X_2, \ldots, X_n$ are independent and identically distributed with 
$E(X) < \infty$, then 
$$
\bar{X} =\frac{1}{n} \sum_{i=1}^n X_i\rightarrow E(X) \quad \text{with probability 1.}
$$

## Central Limit Theorem {.smaller}


Let $X_1, X_2, \ldots, X_n$ be i.i.d., and suppose that 

*  $-\infty < E(X_1) = \mu < \infty$. 
* $Var(X_1) = \sigma^2 < \infty$.

Then 
$$
\frac{\sqrt{n} (\bar{X} - \mu)}{\sigma} \Rightarrow N(0,1)
$$
where $\Rightarrow$ denotes convergence in distribution.

## Properties of Estimators {.smaller}

### Sample Estimates

It can be shown that both the sample mean and sample standard deviation are 
unbiased estimators.
$$
E(\bar{X}) = E(X), \quad E(s^2) = \sigma^2
$$
where $s^2 = \frac{\sum (X_i - \bar{X})^2}{n-1}$.

## Confidence Intervals for Mean {.smaller}

To obtain a $(1-\alpha)100%$ confidence interval for $\mu$, we use the following 
formula, from the CLT:

$$
\bar{X} \pm z_{1-\alpha/2} \frac{s}{\sqrt{n}}
$$

## Confidence Intervals for Probability {.smaller}

$$
X = 
\begin{cases}
1 & \text{with probability $p$} \\
0 & \text{with probability $1- p$}
\end{cases}
$$

In this case, the formula for the CI becomes 
$$
\bar{X} \pm z_{1-\alpha/2} \sqrt{\frac{\bar{X}(1-\bar{X})}{n}}
$$

## Pseudo-Random Number Generators {.smaller}

* Both R and Python contain built-in routines for generating random variables from
  the "named" distributions, 
* PRNGs are routines that generate sequences of deterministic numbers with very very 
  long cycles.
* In both software, we can set the "seed". 

## Random Variable Generation {.smaller}

### R code 

```{r r-rng-1}
#| fig-align: center
#| out-width: 50%
set.seed(2137)

opar <- par(mfrow=c(1,3))
Y <- rgamma(50, 2, 3)
hist(Y)

W <- rpois(50, 1.3) # 50 obs from Pois(1.3)
barplot(table(W))

Z <- rbinom(50, size=2, 0.3) # 50 obs from Binom(2, 0.3)
barplot(table(Z))

par(opar)
```

## Random Variable Generation {.smaller}

### Python code 

```{python py-rng-1}
#| fig-align: center
#| out-width: 50%
#Python
import numpy as np
import pandas as pd
from scipy.stats import binom, gamma, norm, poisson
from scipy import stats
import matplotlib.pyplot as plt

rng = np.random.default_rng(2137)
fig, ax = plt.subplots(1, 3, figsize=(8,4))

ax1 = plt.subplot(131)
r = gamma.rvs(2, 3, size=50, random_state=rng)
ax1.hist(r);

ax1 = plt.subplot(132)
r = poisson.rvs(1.3, size=50, random_state=rng)
ax1.hist(r);

ax1 = plt.subplot(133)
r = binom.rvs(2, 0.3, size=50, random_state=rng)
ax1.hist(r);
```

## Monte-Carlo Integration

* Suppose we wish to evaluate
$$
\int_{-\infty}^{\infty} h(x) f(x) \text{d}x
$$
  where $f(x)$ is a pdf. 
* This is in fact equal to $E(h(X))$, where $X \sim f$.
* Everything depends on:
    1. Being able to introduce a pdf to the integral
    2. Being to able to simulate from that pdf. 

## Monte Carlo Integration over (0,1)

Suppose Suppose we wish to evaluate
$$
\theta = \int_0^1 e^{2x} dx = \int_0^1 e^{2x} \cdot 1\; dx 
$$

We can identify that this is equal to $E(h(X))$ where 

* $X \sim Unif(0,1)$.   
* $h(X) = e^{2x}$

##  MC Integration Example 1 {.smaller}

Thus we can follow this pseudo-code:

1. Generate $X_1,X_2,\ldots,X_n \sim Unif(0,1)$.
2. Estimate the integral using
$$
\frac{1}{2} \sum_{i=1}^n e^{2 X_i}
$$

In this simple case, we can in fact work out analytically that the integral is 
equal to
$$
\frac{1}{n}(e^2 - 1) = 3.195
$$

##  MC Integration Example 1 {.smaller}

### R code 

```{r r-mc-1}
set.seed(2138)
X <- runif(50000, 0, 1)
hX <- exp(2*X)
(mc_est <- mean(hX))
```

##  MC Integration Example 1 {.smaller}

### Python code

```{python py-mc-1}
from scipy.stats import uniform

X = uniform.rvs(0,1, size=50000, random_state=rng)
hX = np.exp(2*X)
hX.mean()
```

## Confidence Intervals {.smaller}

* The usual 95% confidence interval for a mean is given by 
$$
\bar{X} \pm t_{0.025} s/\sqrt{n}
$$
  where $t_{0.025}$ is the 0.025 quantile of the t-distribution with $n-1$ degrees.
* Let us see if it still works if the data is from an asymmetric distribution,
  $Pois(2.5)$.

## Confidence Intervals {.smaller}

#### R code 

```{r r-ci-95}
# R 
set.seed(2139)
output_vec <- rep(0, length=100)
n <- 20
lambda <- 0.5
for(i in 1:length(output_vec)) {
  X <- rpois(n, .5)
  Xbar <- mean(X)
  s <- sd(X)
  t <- qt(0.975, n-1)
  CI <- c(Xbar - t*s/sqrt(n), Xbar + t*s/sqrt(n))
  if(CI[1] < lambda & CI[2] > lambda) {
    output_vec[i] <- 1
  }
}
mean(output_vec)
```

## Confidence Intervals {.smaller}

#### Python code

```{python py-ci-95}
rng = np.random.default_rng(2137)
output_vec = np.zeros(100)
n = 20
lambda_ = 0.5
for i in range(100):
    X = poisson.rvs(0.5, size=15, random_state=rng)
    Xbar = X.mean()
    s = X.std()
    t = norm.ppf(0.975)
    CI = [Xbar - t*s/np.sqrt(n), Xbar + t*s/np.sqrt(n)]
    if CI[0] < lambda_ and CI[1] > lambda_:
        output_vec[i] = 1
output_vec.mean()

```

## Type I Error {.smaller}

* According to the theory of the $t$-test, if both groups have the
  same mean, we should *falsely* reject the null hypothesis 10% of the time 
  if we perform it at 10% significance level. 
* Let us assess if this is what actually happens.

## Type I Error {.smaller}

### R code 

```{r r-test-1a}
generate_one_test <- function(n=100) {
  X <- rnorm(n)
  Y <- rnorm(n)
  t_test <- t.test(X, Y,var.equal = TRUE)
  # extract the p-value from the t_test
  if(t_test$p.value < 0.10) 
    return(1L) 
  else 
    return(0L)
}
```

## Type I Error {.smaller}

### R code 

```{r r-test-1b}
set.seed(11)
output_vec <- vapply(1:2000, 
                     function(x) generate_one_test(), 
                     1L)
mean(output_vec)
```

## Type I Error {.smaller}

### Python code

```{python py-test-1}
def generate_one_test(n=100):
    X = norm.rvs(0, 1, size=n, random_state=rng)
    Y = norm.rvs(0, 1, size=n, random_state=rng)
    t_test = stats.ttest_ind(X, Y, equal_var=True)
    if t_test.pvalue < 0.10:
        return 1
    else:
        return 0
output_vec = np.array([generate_one_test() for j in range(2000)])
output_vec.mean()
```

## Newspaper Inventory {.smaller}

* Suppose that daily demand for newspaper is approximately gamma distributed, 
  with mean 10,000 and variance 1,000,000. 
* The newspaper prints and distributes 11,000 copies each day. 
* The profit on each newspaper sold is $1, and the loss on each unsold newspaper is 
  0.25. 
* Formally, the daily profit function h is

$$
h(X) = 
\begin{cases}
11000 & \text{if } X ≥ 11000 \\
\lfloor X \rfloor + (11000 - \lfloor X \rfloor)(−0.25) & \text{if } X < 11000
\end{cases}
$$

## Newspaper Inventory {.smaller}

### R code 

```{r r-newspaper-1}
# R code to estimate the expected daily profit
set.seed(2141)
n <- 10000
X <- rgamma(n, 100, rate=1/100)
hX <- ifelse(X >= 11000, 11000, floor(X) + (11000 - floor(X)) * (-0.25))
#mean(hX)

# 90% CI for the mean
s <- sd(hX)
q1 <- qnorm(0.95)
CI <- c(mean(hX) - q1*s/sqrt(n), mean(hX) + q1*s/sqrt(n))
cat("The 90% CI for the mean is (", format(CI[1], digits=2, nsmall=2), ", ", 
    format(CI[2], digits=2, nsmall=2), ").\n", sep="")
```

## Newspaper Inventory {.smaller}

### Python code

```{python py-newspaper-1}
n = 10000
X = gamma.rvs(100, scale=100, size=n, random_state=rng)
hX = np.where(X >= 11000, 11000, np.floor(X) + (11000 - np.floor(X)) * (-0.25))

# 90% CI for the mean
Xbar = hX.mean()
s = hX.std()
t = norm.ppf(0.95)
CI = [Xbar - t*s/np.sqrt(n), Xbar + t*s/np.sqrt(n)]
print(f"The 90% CI for the mean is ({CI[0]: .3f}, {CI[1]: .3f}).")
```

## Permutation test
The permutation test is applicable in such a situation. It makes no distributional
assumptions whatsoever on the data. Here is pseudo-code for how it works:

1. Compute the difference in group means. This observed difference is the test 
   statistic.
2. Treating the observed values as fixed, combine the two vectors of observations.
3. Permute the observations, and then re-assign them to the two groups.
4. Compute the difference between the group means.
5. Repeat steps 2 - 4 multiple times (order of 1000). 


## Abalone data permutation {.smaller}

```{r abalone-2a}
abl <- read.csv("data/abalone_sub.csv")
x <- abl$viscera[abl$gender == "M"]
y <- abl$viscera[abl$gender == "F"]
d1 <- mean(x)  - mean(y)
print(d1)
```

## Abalone data permutation {.smaller}

```{r abalone-2b}
generate_one_perm <- function(x, y) {
  n1 <- length(x)
  n2 <- length(y)
  xy <- c(x,y)
  xy_sample <- sample(xy)
  d1 <- mean(xy_sample[1:n1]) - mean(xy_sample[-(1:n1)])
  d1
}
```

## Abalone data permutation {.smaller}

```{r abalone-2c}
sampled_diff <- replicate(2000, generate_one_perm(x,y))
hist(sampled_diff)

(p_val <- 2*mean(sampled_diff > d1))
```

## Bootstrapping {.smaller}

```{r}
library(MASS)

mean(chem)
t.test(chem)
## [1] 4.280417
```

## Bootstrapping {.smaller}

```{r}
library(boot)

stat_fn <- function(d, i) {
  b <- mean(d[i], trim=0.1)
  b
}
boot_out <- boot(chem, stat_fn, R = 1999, stype="i")
# Returns two types of bootstrap intervals:
boot.ci(boot.out = boot_out, type=c("perc", "bca"))
```
