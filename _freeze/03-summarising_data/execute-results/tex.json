{
  "hash": "36897d0e40f1cc1d973516d70b714b42",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Exploring Quantitative Data\"\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n## Introduction\n\nThis is the first topic where we are going to see how to perform statistical\nanalysis using two software: R and Python. Every language has its strengths and\nweaknesses, so instead of attempting to exactly replicate the same chart/output\nin each software, we shall try to understand their respective approaches better.\n\nOur end goal is to analyse data. Toward that end, we should be versatile and\nadaptable. Focus on learning how to be fast and productive in whichever\nenvironment you are told to work in. If you have a choice, then be aware of what\neach framework can do best, so that you can choose the right one.\n\nAlthough it is a simplistic view, @fig-sum-1 provides a\nuseful taxonomy of the types of columns we might have in our dataset. Having at\nleast an initial inkling of the type of data matters, because it helps decide\nwhat type of summary to generate or what type of plot to make. Quantitative data \nare sometimes also referred to as *numerical data*.\n\n![Data types](figs/summ_data-01.png){#fig-sum-1 fig-alt=\"Data types\" fig-align=\"center\" width=\"60%\"}\n\nThere are two main ways of summarising data: numerically and graphically. This topic\nwill cover:\n\n1.  Numerical summaries for univariate quantitative variables.\n2.  Numerical summary for association between two quantitative variables.\n3.  Useful graphs for univariate and bivariate quantitative variables.\n\nTechniques for categorical variables will be covered in @sec-cda.\n\nBefore proceeding, let us introduce one of the datasets that we'll be using in\nthis textbook. The dataset comes from the\n[UCI Machine Learning Repository](https://archive.ics.uci.edu/), which is a \nvery useful place to get datasets for practice. \n\n::: {style=\"background-color: #D5D1D164; padding: 20px\" #exm-stud-perf-intro}\n\n### Student Performance: Dataset Introduction\n\\index{Student performance!description}\n\nThe full dataset can be downloaded from \n[this page](https://archive.ics.uci.edu/dataset/320/student+performance). \nOnce you unzip the file, you will find two `csv` files in the `student/` folder:\n\n* `student-mat.csv` (performance in Mathematics)\n* `student-por.csv` (performance in Portugese)\n\nEach dataset was collected using school reports and questionnaires. Each row\ncorresponds to a student. The columns include student grades, demographic\ninformation, and other social and school-related information. Each file\ncorresponds to the students' performance in one of the two subjects. For more\ninformation, you can refer to @cortez2008using.\n\n| #  | Feature    | Description (Type)                                   | Details                                                                                                        |\n|----|------------|------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|\n| 1  | school     | student's school (binary)                            | \"GP\" - Gabriel Pereira, \"MS\" - Mousinho da Silveira                                                            |\n| 2  | sex        | student's sex (binary)                               | \"F\" - female, \"M\" - male                                                                                       |\n| 3  | age        | student's age (numeric)                              | from 15 to 22                                                                                                  |\n| 4  | address    | student's home address type (binary)                 | \"U\" - urban, \"R\" - rural                                                                                       |\n| 5  | famsize    | family size (binary)                                 | \"LE3\" - less or equal to 3, \"GT3\" - greater than 3                                                             |\n| 6  | Pstatus    | parent's cohabitation status (binary)                | \"T\" - living together, \"A\" - apart                                                                             |\n| 7  | Medu       | mother's education (numeric)                         | 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education, 4 - higher education|\n| 8  | Fedu       | father's education (numeric)                         | 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education, 4 - higher education|\n| 9  | Mjob       | mother's job (nominal)                               | teacher, health, civil services, at_home, other                                                                |\n| 10 | Fjob       | father's job (nominal)                               | teacher, health, civil services, at_home, other                                                                |\n| 11 | reason     | reason to choose this school (nominal)               | close to home, school reputation, course preference, other                                                     |\n| 12 | guardian   | student's guardian (nominal)                         | mother, father, other                                                                                          |\n| 13 | traveltime | home to school travel time (numeric)                 | 1 - <15 min, 2 - 15 to 30 min, 3 - 30 min to 1 hour, 4 - >1 hour                                               |\n| 14 | studytime  | weekly study time (numeric)                          | 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, 4 - >10 hours                                                |\n| 15 | failures   | number of past class failures (numeric)              | n if 1<=n<3, else 4                                                                                            |\n| 16 | schoolsup  | extra educational support (binary)                   | yes or no                                                                                                      |\n| 17 | famsup     | family educational support (binary)                  | yes or no                                                                                                      |\n| 18 | paid       | extra paid classes within the course subject (Math or Portuguese) (binary) | yes or no                     |\n| 19 | activities | extra-curricular activities (binary)                 | yes or no                                                                                                      |\n| 20 | nursery    | attended nursery school (binary)                     | yes or no                                                                                                      |\n| 21 | higher     | wants to take higher education (binary)              | yes or no                                                                                                      |\n| 22 | internet   | Internet access at home (binary)                     | yes or no                                                                                                      |\n| 23 | romantic   | with a romantic relationship (binary)                | yes or no                                                                                                      |\n| 24 | famrel     | quality of family relationships (numeric)            | from 1 - very bad to 5 - excellent                                                                             |\n| 25 | freetime   | free time after school (numeric)                     | from 1 - very low to 5 - very high                                                                             |\n| 26 | goout      | going out with friends (numeric)                     | from 1 - very low to 5 - very high                                                                             |\n| 27 | Dalc       | workday alcohol consumption (numeric)                | from 1 - very low to 5 - very high                                                                             |\n| 28 | Walc       | weekend alcohol consumption (numeric)                | from 1 - very low to 5 - very high                                                                             |\n| 29 | health     | current health status (numeric)                      | from 1 - very bad to 5 - very good                                                                             |\n| 30 | absences   | number of school absences (numeric)                  | from 0 to 93                                                                                                   |\n\nIn the explanatory variables above, notice that although several variables have\nbeen stored in the dataset file as numbers, they are in fact \n*categorical variables*. Examples of these are variables 24 to 29. However, it \ndoes seem fair to treat the three output columns as numeric. G3 is the main output\nvariable.\n\n| #  | Feature | Description (Type)               | Details                    |\n|----|---------|----------------------------------|----------------------------|\n| 31 | G1      | first period grade (numeric)     | from 0 to 20               |\n| 32 | G2      | second period grade (numeric)    | from 0 to 20               |\n| 33 | G3      | final grade (numeric, output target) | from 0 to 20           |\n\n:::\n\n## Numerical Summaries\n\nNumerical summaries include:\n\n1. Basic information about the data, e.g. number of observations and missing \n   values.\n2. Measures of central tendency, e.g. mean, median\n3. Measures of spread, e.g. standard deviation, IQR (interquartile range), range.\n\n::: {style=\"background-color: #D5D1D164; padding: 20px\" #exm-stud-perf-num}\n\n### Student Performance: Numerical Summaries\n\\index{Student performance!numerical summaries}\n\nLet us read in the dataset and generate numerical summaries of the output\nvariable of interest (G3).\n\n::: {.panel-tabset}\n\n#### R code \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstud_perf <- read.table(\"data/student/student-mat.csv\", sep=\";\", \n                        header=TRUE)\nsummary(stud_perf$G3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    8.00   11.00   10.42   14.00   20.00 \n```\n\n\n:::\n\n```{.r .cell-code}\nsum(is.na(stud_perf$G3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\n\n\n\n\n#### Python code\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport numpy as np\n\nstud_perf  = pd.read_csv(\"data/student/student-mat.csv\", delimiter=\";\")\nstud_perf.G3.describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ncount    395.000000\nmean      10.415190\nstd        4.581443\nmin        0.000000\n25%        8.000000\n50%       11.000000\n75%       14.000000\nmax       20.000000\nName: G3, dtype: float64\n```\n\n\n:::\n\n```{.python .cell-code}\n#stud_perf.G3.info()\n```\n:::\n\n\n\n\n\n\n:::\n\nFrom the output, we can understand that we have 395 observations, ranging from 0\nto 20. I would surmise that the data is more or less symmetric in the middle \n(distance from 3rd-quartile to median is identical to distance from median to \n1st-quartile). There are no missing values in the data.\n\nHowever, summaries of a single variable are rarely useful since we do not have \na basis for comparison. In this dataset, we are interested in how the grade varies\nwith one or some of the *other* variables. Let's begin with Mother's education.\n\n::: {.panel-tabset}\n\n#### R code \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nround(aggregate(G3 ~ Medu, data=stud_perf, FUN=summary), 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Medu G3.Min. G3.1st Qu. G3.Median G3.Mean G3.3rd Qu. G3.Max.\n1    0    9.00      12.00     15.00   13.00      15.00   15.00\n2    1    0.00       7.50     10.00    8.68      11.00   16.00\n3    2    0.00       8.00     11.00    9.73      13.00   19.00\n4    3    0.00       8.00     10.00   10.30      13.00   19.00\n5    4    0.00       9.50     12.00   11.76      15.00   20.00\n```\n\n\n:::\n\n```{.r .cell-code}\ntable(stud_perf$Medu)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  0   1   2   3   4 \n  3  59 103  99 131 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n#### Python code\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nstud_perf[['Medu', 'G3']].groupby('Medu').describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         G3                                                  \n      count       mean       std  min   25%   50%   75%   max\nMedu                                                         \n0       3.0  13.000000  3.464102  9.0  12.0  15.0  15.0  15.0\n1      59.0   8.677966  4.364594  0.0   7.5  10.0  11.0  16.0\n2     103.0   9.728155  4.636163  0.0   8.0  11.0  13.0  19.0\n3      99.0  10.303030  4.623486  0.0   8.0  10.0  13.0  19.0\n4     131.0  11.763359  4.267646  0.0   9.5  12.0  15.0  20.0\n```\n\n\n:::\n:::\n\n\n\n\n\n\n:::\n\nNow we begin to understand the context of G3 a little better. As the education\nlevel of the mother increases, the mean does increase. The middle 50-percent of\nthe grade does seem to increase as well. The exception is the case where the\nmother has no education, but we can see that there are only 3 observations in\nthat category, so we should not read too much into it.\n\n:::\n\n\nHere are some things to note about numerical summaries: \n\n*   If the mean and the median are close to each other, it indicates that the distribution of \n    the data is close to symmetric.\n*   The mean is sensitive outliers but the median is not. We shall see more about \n    this in @sec-robust.\n*   When the mean is much larger than the median, it suggests that there could be a few very        large observations. It has resulted in a *right-skewed* distribution. Conversely, if \n    the mean is much smaller than the median, we probably have a *left-skewed* distribution. \n  \nWhile numerical summaries provide us with some basic information about the data,\nthey also leave out a lot. Even for experts, it is possible to have a wrong \nmental idea about the data from the numerical summaries alone. For instance,\nall three histograms in @fig-sum-2 have a mean of 0 and standard deviation of 1!\n\n![Three vastly different datasets, all with mean 0 and s.d. 1](figs/summ_data-02.png){#fig-sum-2 fig-alt=\"3 histograms\" fig-align=\"center\" width=\"65%\"}\n\nThat's why we have to turn to *graphics* as well, in order to summarise our\ndata.\n\n## Graphical Summaries\n\n### Histograms \n\nThe first chart type we shall consider is a histogram. A histogram is a graph\nthat uses bars to portray the frequencies or relative frequencies of the\npossible outcomes for a quantitative variable.\n\nWhen we create a histogram, here are some things that we look for:\n\n1.  *What is the overall pattern?*: Do the data cluster together, or is there a \n    gap such that one or more observations deviate from the rest?\n2.  *Are there any suspected outliers?* See @fig-hist-outliers.\n3.  *Do the data have a single mound or peak?* If yes, then we have what is \n    known as a unimodal distribution. Data with two 'peaks' are referred to as \n    bimodal, and data with many peaks are referred to as multimodal. See \n    @fig-hist-bimodal.\n4.  *Is the distribution symmetric or skewed?* See @fig-hist-skewed-egs.\n\n::: {layout=\"[[1,1], [1]]\"}\n![Histogram with outliers](figs/summ_data-03.png){#fig-hist-outliers}\n\n![Bimodal histogram](figs/summ_data-04.png){#fig-hist-bimodal}\n\n![Skewed histograms](figs/summ_data-05.png){#fig-hist-skewed-egs}\n:::\n\n\n\n\n\n\n{{< pagebreak >}}\n\n\n\n\n\n\n\n\n\n\n\n::: {style=\"background-color: #D5D1D164; padding: 20px\" #exm-stud-perf-hist}\n\n### Student Performance: Histograms\n\\index{Student performance!histograms}\n\nNow let us return to the student performance dataset.\n\n::: {.panel-tabset}\n\n#### R code \n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhist(stud_perf$G3, main=\"G3 histogram\", xlab=\"G3 scores\")\n```\n\n::: {.cell-output-display}\n![R: Histogram of G3 scores](03-summarising_data_files/figure-pdf/fig-r-histogram-g3-1.pdf){#fig-r-histogram-g3 fig-align='center' fig-pos='H' width=70%}\n:::\n:::\n\n\n\n\n\n\n#### Python code\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\nfig = stud_perf.G3.hist(grid=False)\nfig.set_title('G3 histogram')\nfig.set_xlabel('G3 scores');\n```\n\n::: {.cell-output-display}\n![Py: Histogram of G3 scores](03-summarising_data_files/figure-pdf/py-stud-perf-3-1.pdf){fig-align='center' fig-pos='H' width=70%}\n:::\n:::\n\n\n\n\n\n\n:::\n\n::: {.callout-note}\nDo you notice any differences between the two histograms? \n:::\n\nIn general, we now have a little more information to accompany the 5 number summaries.\nIt appears that the distribution is not a basic unimodal one. There is a large \nspike of about 40 students who scored very low scores.\n\nAs we mentioned earlier, it is not useful to inspect a histogram in a silo.\nHence we shall condition on Mother's education once more, to create separate\nhistograms for each group. Remember that this is a case where the response\nvariable `G3` is quantitative, and the explanatory variable `Medu` is ordinal.\n\n::: {.panel-tabset}\n\n#### R code \n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(lattice)\nhistogram(~G3 | Medu, data=stud_perf, type=\"density\",\n          main=\"G3 scores, by Medu levels\", as.table=TRUE)\n```\n\n::: {.cell-output-display}\n![R: Lattice plot of G3 scores by Medu](03-summarising_data_files/figure-pdf/fig-r-lattice-g3-3.pdf){#fig-r-lattice-g3 fig-align='center' fig-pos='H' width=80%}\n:::\n:::\n\n\n\n\n\n\n#### Python code\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\nstud_perf.G3.hist(by=stud_perf.Medu, figsize=(15,10), density=True, \n                  layout=(2,3));\n```\n\n::: {.cell-output-display}\n![Py: Lattice plot of G3 scores by Medu](03-summarising_data_files/figure-pdf/py-stud-perf-4-1.pdf){fig-align='center' fig-pos='H' width=80%}\n:::\n:::\n\n\n\n\n\n\n:::\n\nAlthough the heights of the panels in the two versions are not identical, we\ncan, by looking at either one, see that the proportion of 0-scores reduces as\nthe mother's education increases. Perhaps this is reading too much into the\ndataset, but there seem to be more scores on the higher end for highest educated\nmothers.\n\n:::\n\n### Density Plots\n\nHistograms are not perfect - when using them, we have to experiment with the bin \nsize since this could mask details about the data. It is also easy to get \ndistracted by the blockiness of histograms. An alternative to histograms is the\nkernel density plot. Essentially, this is obtained by smoothing the heights of\nthe rectangles in a histogram.\n\nSuppose we have observed an i.i.d sample $x_1, x_2, \\ldots, x_n$ from a\ncontinuous pdf $f(\\cdot)$. Then the kernel density estimate at $x$ is given by\n\n$$\n\\hat{f}(x)  = \\frac{1}{nh} \\sum_{i=1}^n K \\left( \\frac{x - x_i}{h} \\right)\n$$\nwhere\n\n*   $K$ is a density function. A typical choice is the standard normal. The kernel \n    places greater weights on nearby points (to $x$).\n*   $h$ is a bandwidth, which determines which of the nearest points are used. The \n    effect is similar to the number of bins in a histogram.\n\n::: {style=\"background-color: #D5D1D164; padding: 20px\" #exm-stud-perf-dist}\n\n### Student Performance: Density Estimates\n\\index{Student performance!density plots}\n\nHere is how we can make density plots with R and Python for the G3 scores.\n\n::: {.panel-tabset}\n\n#### R code \n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndensityplot(~G3, groups=Medu, data=stud_perf, auto.key = TRUE, \n            main=\"G3 scores, by Medu\", bw=1.5)\n```\n\n::: {.cell-output-display}\n![R: Estimated densities for G3 scores, by Medu](03-summarising_data_files/figure-pdf/r-stud-perf-5-3.pdf){fig-align='center' fig-pos='H' width=80%}\n:::\n:::\n\n\n\n\n\n\n#### Python code\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\nimport matplotlib.pyplot as plt\nf, axs = plt.subplots(2, 3, squeeze=False, figsize=(15,6))\nout2 = stud_perf.groupby(\"Medu\")\nfor y,df0 in enumerate(out2):\n    tmp = plt.subplot(2, 3, y+1)\n    df0[1].G3.plot(kind='kde')\n    tmp.set_title(df0[0])\n```\n\n::: {.cell-output-display}\n![Py: Estimated densities for G3 scores, by Medu](03-summarising_data_files/figure-pdf/py-stud-perf-5-1.pdf){fig-align='center' fig-pos='H' width=80%}\n:::\n:::\n\n\n\n\n\n\n:::\n\nAs you can see, with density plots it is also possible to overlay them for closer\ncomparison. This is not possible with histograms without some transparency in the \nrectangle colours.\n\n:::\n\n### Boxplots \n\nA boxplot provides a skeletal representation of a distribution. Boxplots are\nvery well suited for comparing multiple groups.\n\nHere are the steps for drawing a boxplot: \n\n1.  Determine $Q_1$, $Q_2$ and $Q_3$. The box is made from $Q_1$ and $Q_3$. The \n    median is drawn as a line or a dot within the box.\n2.  Determine the max-whisker reach: $Q_3 + 1.5 \\times IQR$; the min-whisker reach by \n    $Q_1 âˆ’ 1.5 \\times IQR$.\n3.  Any data point that is out of the range from the min to max whisker reach is \n    classified as a *potential outlier*.\n4.  Excluding the potential outliers, the maximum point determines the *upper whisker* \n    and the minimum point determines the *lower whisker* of a boxplot.\n   \nA boxplot helps us to identify the median, lower and upper quantiles and outlier(s) \n(see @fig-sum-8).\n\n![Boxplot construction](figs/summ_data-08.png){#fig-sum-8 fig-alt=\"Boxplot construction\" fig-align=\"center\" width=\"70%\"}\n\n::: {style=\"background-color: #D5D1D164; padding: 20px\" #exm-stud-perf-box}\n\n### Student Performance: Boxplots\n\\index{Student performance!boxplots}\n\nThis time, instead of using mother's education, we use the number of times a\nstudent goes out (`goout`) as the explanatory variable. From the boxplot\noutputs, it appears there is no strong strictly increasing/decreasing trend\nassociated with G3. Instead, although the differences between the categories are\nnot large, it seems as though there is an \"optimal\" number of times that\nstudents could go out. Too little and too much going out leads to lower median\nG3 scores.\n\n::: {.panel-tabset}\n\n#### R code \n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbwplot(G3 ~ goout, horizontal = FALSE, main=\"G3 scores, by goout\", \n       xlab=\"No. of times the student goes out per week\",\n       data=stud_perf)\n```\n\n::: {.cell-output-display}\n![R: Boxplot of G3 scores, by gout variable](03-summarising_data_files/figure-pdf/r-stud-perf-6-3.pdf){fig-align='center' fig-pos='H' width=70%}\n:::\n:::\n\n\n\n\n\n\n#### Python code\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\nstud_perf.plot.box(column='G3', by='goout', \n                   xlabel='No. of times student goes out per week');\n```\n\n::: {.cell-output-display}\n![Py: Boxplot of G3 scores, by gout variable](03-summarising_data_files/figure-pdf/py-stud-perf-6-1.pdf){fig-align='center' fig-pos='H' width=70%}\n:::\n:::\n\n\n\n\n\n\n:::\n\n\n:::\n\n### QQ-plots\n\nFinally, we turn to QQ-plots. A Quantile-Quantile plot is a graphical diagnostic \ntool for assessing if a dataset follows a particular distribution. Most of the time\nwe would be interested in comparing against a Normal distribution. \n\nA QQ-plot plots the standardized sample quantiles against the theoretical\nquantiles of a N(0; 1) distribution. If the points fall on a straight line, then we \nsay there is evidence that the data comes from a Normal distribution.\n\nEspecially for unimodal datasets, the points in the middle will typically fall\nclose to the line. The value of a QQ-plot is in judging if the tails of the data\nare fatter or thinner than the tails of the Normal.\n\n\n\n\n\n\n::: {#fig-qq-1 .cell layout-ncol=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![Thinner than Normal](03-summarising_data_files/figure-pdf/fig-qq-1-3.pdf){#fig-qq-1-1 fig-align='center'}\n:::\n\n::: {.cell-output-display}\n![Fatter than Normal](03-summarising_data_files/figure-pdf/fig-qq-1-4.pdf){#fig-qq-1-2 fig-align='center'}\n:::\n\nQQ-plots\n:::\n\n\n\n\n\n\n::: {.callout-note}\nPlease be careful! Some software/packages will switch the axes (i.e. plot the\nsample quantiles on the x-axis instead of the y-axis, unlike @fig-qq-1). Please\nobserve and interpret accordingly.\n:::\n\n::: {style=\"background-color: #D5D1D164; padding: 20px\" #exm-concrete-intro}\n\n### Concrete Slump: Dataset Introduction\n\\index{Concrete slump!description}\n\nConcrete is a highly complex material. The slump flow of concrete is not only\ndetermined by the water content, but also by other ingredients. The UCI page for \nthis particular dataset is\n[here](https://archive.ics.uci.edu/dataset/182/concrete+slump+test). The reference\narticle on this dataset is @yeh2007modeling.\n\nThe data set includes 103 data points. There are 7 input variables, and 3 output\nvariables in the data set. These are the input columns in the data, all in \nunits of $kg/m^3$ concrete:\n\n| #   | Feature              | Details                                   |\n|-----|----------------------|-------------------------------------------|\n| 1   | Cement               |                                           |\n| 2   | Slag                 |                                           |\n| 3   | Fly ash              |                                           |\n| 4   | Water                |                                           |\n| 5   | SP                   | A super plasticizer to improve consistency. |\n| 6   | Coarse Aggr.         |                                           |\n| 7   | Fine Aggr.           |                                           |\n\nThere are three output variables in the dataset. You can read more \nabout Slump and Flow from this \n[wikipedia page](https://en.wikipedia.org/wiki/Concrete_slump_test).\n\n| #   | Feature                     | Units             |\n|-----|-----------------------------|-------------------|\n| 1   | SLUMP                       | cm                |\n| 2   | FLOW                        | cm                |\n| 3   | 28-day Compressive Strength | MPa               |\n\n::: {.panel-tabset}\n\n#### R code \n\nTo read the data into R:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconcrete <- read.csv(\"data/concrete+slump+test/slump_test.data\")\nnames(concrete)[c(1,11)] <- c(\"id\", \"Comp.Strength\")\n```\n:::\n\n\n\n\n\n\n#### Python code\n\nThe corresponding Python code is:\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nconcrete = pd.read_csv(\"data/concrete+slump+test/slump_test.data\")\nconcrete.rename(columns={'No':'id', \n                         'Compressive Strength (28-day)(Mpa)':'Comp_Strength'},  \n                inplace=True)\n```\n:::\n\n\n\n\n\n\n\n:::\n\n:::\n\nLet us consider the Comp.Strength output variable. The histogram overlay\nin @fig-concrete-1 suggests some skewness and fatter tails than the Normal.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Comparing data with reference Normal (blue)](03-summarising_data_files/figure-pdf/fig-concrete-1-1.pdf){#fig-concrete-1 fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n\n\n::: {style=\"background-color: #D5D1D164; padding: 20px\" #exm-concrete-qq}\n\n### Concrete: QQ-plots\n\\index{Concrete slump!QQ plots}\n\nThe next chart is a QQ-plot, for assessing deviations from Normality.\n\n::: {.panel-tabset}\n\n#### R code \n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nqqnorm(concrete$Comp.Strength)\nqqline(concrete$Comp.Strength)\n```\n\n::: {.cell-output-display}\n![R: QQ plot for compressive strength](03-summarising_data_files/figure-pdf/r-concrete-1-1.pdf){fig-align='center' fig-pos='H' width=70%}\n:::\n:::\n\n\n\n\n\n\n#### Python code\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\nfrom scipy import stats\nimport statsmodels.api as sm\nsm.qqplot(concrete.Comp_Strength, line=\"q\");\n```\n\n::: {.cell-output-display}\n![Py: QQ plot for compressive strength](03-summarising_data_files/figure-pdf/py-concrete-1-1.pdf){fig-align='center' fig-pos='H' width=70%}\n:::\n:::\n\n\n\n\n\n\n:::\n\nThe deviation of the tails does not seem to be that large, judging from the QQ-plot.\n:::\n\n## Correlation \n\nWhen we are studying two quantitative variables, the most common numerical\nsummary to quantify the relationship between them is the correlation\ncoefficient. Suppose that $x_1, x_2, \\ldots, x_n$ and $y_1, \\ldots, y_n$ are two\nvariables from a set of $n$ objects or people. The sample correlation between\nthese two variables is computed as:\n\n$$\nr = \\frac{1}{n-1} \\sum_{i=1}^n \\frac{(x_i - \\bar{x})(y_i - \\bar{y})}{s_x s_y}\n$$\nwhere $s_x$ and $s_y$ are the sample standard deviations. $r$ is an estimate of \nthe correlation between random variables $X$ and $Y$.\n\n::: {layout-nrow=2}\n![Varying linear relations and corresponding $r$-values](figs/summ_data-06.png){#fig-corr-linear fig-align=center out-width=50%}\n\n![Non-linear relations and corresponding $r$-values](figs/summ_data-07.png){#fig-corr-non-linear fig-align=center out-width=50%}\n:::\n\nA few things to note about the value $r$, which is also referred to as the \nPearson correlation:\n\n*   $r$ is always between -1 and 1.\n*   A positive value for $r$ indicates a positive association and a negative value for \n    $r$ indicates a negative association.\n*   Two variables have the same correlation, no matter which one is coded as $X$ and\n    which one is coded as $Y$.\n\n@fig-corr-linear and @fig-corr-non-linear contain sample plots of data and their \ncorresponding $r$ values. Notice how $r$ does not reflect strong non-linear \nrelationships.\n\n\n\n\n\n\n{{< pagebreak >}}\n\n\n\n\n\n\n\n\n\n\n## Scatterplot Matrices\n\\index{Concrete slump!scatterplots and correlation}\n\n::: {style=\"background-color: #D5D1D164; padding: 20px\" #exm-concrete-scatter}\n\n### Concrete: Scatterplots\n\nWhen we have multiple quantitative variables in a dataset, it is common to \ncreate a matrix of scatterplots. This allows for simultaneous inspection of \nbivariate relationships.\n\n::: {.panel-tabset}\n\n#### R code \n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncol_to_use <- c(\"Cement\", \"Slag\", \"Comp.Strength\", \"Water\", \"SLUMP.cm.\",\n                \"FLOW.cm.\")\npairs(concrete[, col_to_use], panel = panel.smooth)\n```\n\n::: {.cell-output-display}\n![R: Scatterplot matrix for concrete dataset](03-summarising_data_files/figure-pdf/r-concrete-2-3.pdf){fig-align='center' fig-pos='H' width=100%}\n:::\n:::\n\n\n\n\n\n\n#### Python code\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\npd.plotting.scatter_matrix(concrete[['Cement', 'Slag', 'Comp_Strength', 'Water', \n                                     'SLUMP(cm)', 'FLOW(cm)']], \n                           figsize=(12,12));\n```\n\n::: {.cell-output-display}\n![Py: Scatterplot matrix for concrete dataset](03-summarising_data_files/figure-pdf/py-concrete-3-1.pdf){fig-align='center' fig-pos='H' width=100%}\n:::\n:::\n\n\n\n\n\n\n:::\n\nWe can see that a few of the variables have several 0 values - cement, slag, slump and \nflow. Water appears to have some relation with slump and with flow.\n\nThe scatterplots allow a visual understanding of the patterns, but it is usually \nalso good to compute the correlation of all pairs of variables. \n\n::: {.panel-tabset}\n\n#### R code \n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(psych)\ncorPlot(cor(concrete[, col_to_use]), cex=0.8, cex.axis=0.6, \n        show.legend = FALSE)\n```\n\n::: {.cell-output-display}\n![R: Heatmap of correlation matrix for concrete data](03-summarising_data_files/figure-pdf/r-concrete-3-3.pdf){fig-align='center' fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n#### Python code\n\nThe interactive heatmap created by Python is only available in the HTML format\nof the textbook.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\ncorr = concrete[['Cement', 'Slag', 'Comp_Strength', 'Water', \n                 'SLUMP(cm)', 'FLOW(cm)']].corr()\ncorr.style.background_gradient(cmap='coolwarm_r')\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<style type=\"text/css\">\n#T_679bf_row0_col0, #T_679bf_row1_col1, #T_679bf_row2_col2, #T_679bf_row3_col3, #T_679bf_row4_col4, #T_679bf_row5_col5 {\n  background-color: #3b4cc0;\n  color: #f1f1f1;\n}\n#T_679bf_row0_col1 {\n  background-color: #cb3e38;\n  color: #f1f1f1;\n}\n#T_679bf_row0_col2, #T_679bf_row3_col4 {\n  background-color: #c5d6f2;\n  color: #000000;\n}\n#T_679bf_row0_col3 {\n  background-color: #f4c6af;\n  color: #000000;\n}\n#T_679bf_row0_col4 {\n  background-color: #f7b89c;\n  color: #000000;\n}\n#T_679bf_row0_col5 {\n  background-color: #f3c8b2;\n  color: #000000;\n}\n#T_679bf_row1_col0, #T_679bf_row1_col2, #T_679bf_row1_col4, #T_679bf_row1_col5, #T_679bf_row2_col1, #T_679bf_row2_col3, #T_679bf_row5_col1 {\n  background-color: #b40426;\n  color: #f1f1f1;\n}\n#T_679bf_row1_col3 {\n  background-color: #ea7b60;\n  color: #f1f1f1;\n}\n#T_679bf_row2_col0 {\n  background-color: #cedaeb;\n  color: #000000;\n}\n#T_679bf_row2_col4 {\n  background-color: #c53334;\n  color: #f1f1f1;\n}\n#T_679bf_row2_col5, #T_679bf_row5_col2 {\n  background-color: #e46e56;\n  color: #f1f1f1;\n}\n#T_679bf_row3_col0 {\n  background-color: #f5c4ac;\n  color: #000000;\n}\n#T_679bf_row3_col1 {\n  background-color: #f29072;\n  color: #f1f1f1;\n}\n#T_679bf_row3_col2 {\n  background-color: #c83836;\n  color: #f1f1f1;\n}\n#T_679bf_row3_col5 {\n  background-color: #96b7ff;\n  color: #000000;\n}\n#T_679bf_row4_col0 {\n  background-color: #f7b194;\n  color: #000000;\n}\n#T_679bf_row4_col1 {\n  background-color: #c12b30;\n  color: #f1f1f1;\n}\n#T_679bf_row4_col2 {\n  background-color: #d0473d;\n  color: #f1f1f1;\n}\n#T_679bf_row4_col3 {\n  background-color: #c7d7f0;\n  color: #000000;\n}\n#T_679bf_row4_col5, #T_679bf_row5_col4 {\n  background-color: #506bda;\n  color: #f1f1f1;\n}\n#T_679bf_row5_col0 {\n  background-color: #f7bca1;\n  color: #000000;\n}\n#T_679bf_row5_col3 {\n  background-color: #9dbdff;\n  color: #000000;\n}\n</style>\n<table id=\"T_679bf\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_679bf_level0_col0\" class=\"col_heading level0 col0\" >Cement</th>\n      <th id=\"T_679bf_level0_col1\" class=\"col_heading level0 col1\" >Slag</th>\n      <th id=\"T_679bf_level0_col2\" class=\"col_heading level0 col2\" >Comp_Strength</th>\n      <th id=\"T_679bf_level0_col3\" class=\"col_heading level0 col3\" >Water</th>\n      <th id=\"T_679bf_level0_col4\" class=\"col_heading level0 col4\" >SLUMP(cm)</th>\n      <th id=\"T_679bf_level0_col5\" class=\"col_heading level0 col5\" >FLOW(cm)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_679bf_level0_row0\" class=\"row_heading level0 row0\" >Cement</th>\n      <td id=\"T_679bf_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n      <td id=\"T_679bf_row0_col1\" class=\"data row0 col1\" >-0.243553</td>\n      <td id=\"T_679bf_row0_col2\" class=\"data row0 col2\" >0.445725</td>\n      <td id=\"T_679bf_row0_col3\" class=\"data row0 col3\" >0.221091</td>\n      <td id=\"T_679bf_row0_col4\" class=\"data row0 col4\" >0.145913</td>\n      <td id=\"T_679bf_row0_col5\" class=\"data row0 col5\" >0.186461</td>\n    </tr>\n    <tr>\n      <th id=\"T_679bf_level0_row1\" class=\"row_heading level0 row1\" >Slag</th>\n      <td id=\"T_679bf_row1_col0\" class=\"data row1 col0\" >-0.243553</td>\n      <td id=\"T_679bf_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n      <td id=\"T_679bf_row1_col2\" class=\"data row1 col2\" >-0.331588</td>\n      <td id=\"T_679bf_row1_col3\" class=\"data row1 col3\" >-0.026775</td>\n      <td id=\"T_679bf_row1_col4\" class=\"data row1 col4\" >-0.284037</td>\n      <td id=\"T_679bf_row1_col5\" class=\"data row1 col5\" >-0.327231</td>\n    </tr>\n    <tr>\n      <th id=\"T_679bf_level0_row2\" class=\"row_heading level0 row2\" >Comp_Strength</th>\n      <td id=\"T_679bf_row2_col0\" class=\"data row2 col0\" >0.445725</td>\n      <td id=\"T_679bf_row2_col1\" class=\"data row2 col1\" >-0.331588</td>\n      <td id=\"T_679bf_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n      <td id=\"T_679bf_row2_col3\" class=\"data row2 col3\" >-0.254235</td>\n      <td id=\"T_679bf_row2_col4\" class=\"data row2 col4\" >-0.223358</td>\n      <td id=\"T_679bf_row2_col5\" class=\"data row2 col5\" >-0.124029</td>\n    </tr>\n    <tr>\n      <th id=\"T_679bf_level0_row3\" class=\"row_heading level0 row3\" >Water</th>\n      <td id=\"T_679bf_row3_col0\" class=\"data row3 col0\" >0.221091</td>\n      <td id=\"T_679bf_row3_col1\" class=\"data row3 col1\" >-0.026775</td>\n      <td id=\"T_679bf_row3_col2\" class=\"data row3 col2\" >-0.254235</td>\n      <td id=\"T_679bf_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n      <td id=\"T_679bf_row3_col4\" class=\"data row3 col4\" >0.466568</td>\n      <td id=\"T_679bf_row3_col5\" class=\"data row3 col5\" >0.632026</td>\n    </tr>\n    <tr>\n      <th id=\"T_679bf_level0_row4\" class=\"row_heading level0 row4\" >SLUMP(cm)</th>\n      <td id=\"T_679bf_row4_col0\" class=\"data row4 col0\" >0.145913</td>\n      <td id=\"T_679bf_row4_col1\" class=\"data row4 col1\" >-0.284037</td>\n      <td id=\"T_679bf_row4_col2\" class=\"data row4 col2\" >-0.223358</td>\n      <td id=\"T_679bf_row4_col3\" class=\"data row4 col3\" >0.466568</td>\n      <td id=\"T_679bf_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n      <td id=\"T_679bf_row4_col5\" class=\"data row4 col5\" >0.906135</td>\n    </tr>\n    <tr>\n      <th id=\"T_679bf_level0_row5\" class=\"row_heading level0 row5\" >FLOW(cm)</th>\n      <td id=\"T_679bf_row5_col0\" class=\"data row5 col0\" >0.186461</td>\n      <td id=\"T_679bf_row5_col1\" class=\"data row5 col1\" >-0.327231</td>\n      <td id=\"T_679bf_row5_col2\" class=\"data row5 col2\" >-0.124029</td>\n      <td id=\"T_679bf_row5_col3\" class=\"data row5 col3\" >0.632026</td>\n      <td id=\"T_679bf_row5_col4\" class=\"data row5 col4\" >0.906135</td>\n      <td id=\"T_679bf_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n    </tr>\n  </tbody>\n</table>\n```\n\n:::\n:::\n\n\n\n\n\n\n:::\n\nThe plots you see above are known as heatmaps. They enable us to pick out \ngroups of variables that are similar to one another. As you can see from the \nblue block in the lower right corner, `Water`, `SLUMP.cm` and `FLOW.cm` are \nvery similar to one another.\n\n:::\n\n## References\n\n### Website References\n\n1.  [UCI Machine Learning Repository](https://archive.ics.uci.edu/): This site is \n    an invaluable learning resource for data analysts. It contains several datasets\n    for practice. In this chapter, we used the following two:\n    * [Student Performance Dataset](https://archive.ics.uci.edu/dataset/320/student+performance).\n    * [Concrete Dataset](https://archive.ics.uci.edu/dataset/182/concrete+slump+test)\n3.  [Kernel density estimation](https://en.wikipedia.org/wiki/Kernel_density_estimation): Wikipedia contains a good overview explanation of the technique. \n\n## Exercises\n\nIn the questions, do try to answer each question using both R and Python whenever\npossible.\n\n1.  From @fig-r-histogram-g3 alone, can you make a rough guess: What proportion of \n    students scored 6 or less?\n2.  Divide the concrete data into two subsets - one with Water less than or equal to \n    200 and one with Water greater than 200. Compute the Pearson correlations with\n    compressive strength. How different are these values with the value for the full\n    dataset?\n3.  Remove all rows with zero values for Slag from the concrete dataset. Create \n    a QQ-plot for Slag and assess if the data is Normal.\n4.  How does bandwidth affect a density estimate (`bw` argument)? Experiment with \n    different values to understand more.\n5.  Create numerical summaries of `G3` scores, by `goout`, and compare the groups.",
    "supporting": [
      "03-summarising_data_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}